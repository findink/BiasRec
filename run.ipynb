{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dataProcess, graph\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import dgl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from tracemalloc import start\n",
    "import dgl, torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.sparse as sp\n",
    "import tqdm\n",
    "import argparse\n",
    "from utils import dataProcess,graph\n",
    "from model import embed, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    torch.manual_seed(36)\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--dataset\",default=\"epinions\")\n",
    "    parser.add_argument(\"--r1\",default=0.01,type=float)\n",
    "    parser.add_argument(\"--r2\",default=0.01,type=float)\n",
    "    parser.add_argument(\"--r3\",default=0.1,type=float)\n",
    "    \n",
    "\n",
    "    args = parser.parse_args(args=[])\n",
    "    r1 , r2, r3 = args.r1, args.r2, args.r3\n",
    "    min_test_rmse , min_test_mae = 5.0, 5.0\n",
    "\n",
    "    # load and clean data from xx_rating.mat and xx_trust.mat file\n",
    "    dataset = args.dataset\n",
    "    dataset = \"ciao\"\n",
    "    rating_data, trust_data =  dataProcess.get_data_from_matfile(dataset)\n",
    "    # rating_data, trust_data = dataProcess.load_data_yelp()\n",
    "    # rating_data = dataProcess.load_data_1m()\n",
    "    # trust_data = None\n",
    "    rating_data, trust_data , user_num, item_num = dataProcess.data_clean(rating_data, trust_data)\n",
    "\n",
    "    rating_data_train, rating_data_valid, rating_data_test = dataProcess.data_split(rating_data,train_ratio=0.8)\n",
    "    user_info, item_info = dataProcess.stat_info(rating_data_train, user_num,  item_num)\n",
    "    item_avg ,item_std , user_bias  = dataProcess.get_some_stat(user_info, item_info)\n",
    "    rating_data_train = dataProcess.add_pref_col(rating_data_train, user_info, item_info)\n",
    "    trust_data = dataProcess.add_trust_strength(trust_data, rating_data_train)\n",
    "    \n",
    "\n",
    "    node_num = user_num + item_num\n",
    "\n",
    "    \n",
    "    # generate graph \n",
    "    rate_g  = graph.rating_graph_gen(rating_data_train, user_num, item_num)\n",
    "    trust_g = graph.trust_graph_gen(trust_data, user_num)\n",
    "    union_g = graph.union_graph_gen(rating_data_train, trust_data, user_num, item_num)\n",
    "    # g = union_g  # use (rate_g + trust_g) or union_g\n",
    "    g = rate_g\n",
    "    # g = union_g\n",
    "    edge_rate = g.edata['p']\n",
    "    edge_rate = torch.unsqueeze(edge_rate,0).float().T\n",
    "    # g = graph.graph_add_aug_r(g, user_info, item_info)\n",
    "\n",
    "    \n",
    "\n",
    "    epoch = 60\n",
    "    batch_size = 512  # each batch use  batch_size users records.\n",
    "    batch_num = (user_num + batch_size -1) // batch_size \n",
    "    hide_dims = 32\n",
    "    \n",
    "\n",
    "    device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "    print(\"device: \", device)\n",
    "    g = g.to(device)\n",
    "    trust_g = trust_g.to(device)\n",
    "    edge_rate = edge_rate.to(device)\n",
    "    node_onehot_tensor = dataProcess.get_node_onehot_tensor(node_num).to(device)\n",
    "    node_embed_layer =  embed.NodeEmbed(node_num, hide_dims, g, trust_g).to(device)\n",
    "    pref_predict_layer = predict.prefPredictLayer(hide_dims).to(device)\n",
    "    item_avg ,item_std , user_bias  =  torch.tensor(item_avg).float().to(device), torch.tensor(item_std).float().to(device), torch.tensor(user_bias).float().to(device)\n",
    "    user_group_ratio = torch.tensor([0.1]*user_num).to(device)\n",
    "    item_avg.requires_grad = True\n",
    "    item_std.requires_grad = True\n",
    "    user_group_ratio.requires_grad = True\n",
    "    user_bias.requires_grad = True\n",
    "\n",
    "    loss_func = nn.MSELoss()\n",
    "    r1, r2 ,r3  = 0.01, 0.01, 0.01 # r1 < 0.001, r2 < 0.01\n",
    "    opt = torch.optim.Adam([\n",
    "        {'params': node_embed_layer.parameters(), 'weight_decay': 0.001},\n",
    "        # {'params': node_embed_layer.w.parameters(), 'weight_decay': 0.0001,'lr':0.005}, # < 0.01\n",
    "        # {'params': node_embed_layer.gat.parameters(), 'weight_decay': r2}, \n",
    "        # {'params': node_embed_layer.pref_embeding.parameters(), 'weight_decay': 0.001,'lr':0.0005}, \n",
    "        # {'params': node_embed_layer.trust_embeding.parameters(), 'weight_decay': 0.001,'lr':0.0005}, \n",
    "\n",
    "        # {'params': node_embed_layer.egat.parameters(), 'weight_decay': 0.01,'lr':0.0001}, \n",
    "        # {'params': node_embed_layer.egat2.parameters(), 'weight_decay': 0.01,'lr':0.0001}, \n",
    "        # {'params': node_embed_layer.embeds_user_agg.parameters(), 'weight_decay': 0.01}, \n",
    "        # {'params': node_embed_layer.embeds_item_agg.parameters(), 'weight_decay': 0.01}, \n",
    "        \n",
    "        # {'params': node_embed_layer.egat2.parameters(), 'weight_decay': r2}, \n",
    "        # {'params': node_embed_layer2.gat.parameters(), 'weight_decay': r2}, \n",
    "        # {'params': node_embed_layer.egat3.par ameters(), 'weight_decay': r2},\n",
    "\n",
    "        {'params':pref_predict_layer.mlp.parameters(), 'weight_decay': 0.001, 'lr':0.001}, # lr <0.01\n",
    "        {'params':user_bias, 'lr':0.01},\n",
    "        # {'params':item_avg, 'lr':0.001},\n",
    "        # {'params':item_std, 'lr':0.01},\n",
    "        {'params':user_group_ratio, 'lr':0.001},\n",
    "        # {'params':pref_predict_layer.info_mlp2.parameters(), 'weight_decay': 0.04}, # > 0.04\n",
    "        # {'params':pref_predict_layer.final.parameters(), 'weight_decay': 0.04},\n",
    "        # {'params':pref_predict_layer.parameters(), 'weight_decay': 0.04},\n",
    "        # {'params':predict_layer.parameters(), 'weight_decay': r3},\n",
    "        ],\n",
    "        lr=0.001)\n",
    "\n",
    "    np.random.seed(36)\n",
    "    user_ids_shuffle_list = np.random.permutation(user_num)\n",
    "    user_rateRecords_dict = dataProcess.get_user_rateRecords_dict(rating_data_train)\n",
    "\n",
    "    print(\"===start train===\")\n",
    "    for i in range(epoch):\n",
    "        epoch_loss = 0\n",
    "        for j in range(batch_num):\n",
    "            user_start_idx, user_end_idx  = j * batch_size, min((j+1)*batch_size, user_num)\n",
    "            batch_user_ids = user_ids_shuffle_list[user_start_idx : user_end_idx]\n",
    "            batch = dataProcess.get_records(user_rateRecords_dict, batch_user_ids)\n",
    "\n",
    "            batch_user, batch_item = batch[:,0], batch[:,1]\n",
    "            batch_rate = torch.tensor(batch[:,2]).float().to(device)\n",
    " \n",
    "            user_embeds,group_embeds, item_embeds  = node_embed_layer(node_onehot_tensor)   # one-hot  ==> user_embed, item_embed\n",
    "            \n",
    "            batch_user_embed, batch_group_embeds, batch_item_embed = user_embeds[batch_user], group_embeds[batch_user],item_embeds[batch_item]\n",
    "\n",
    "            batch_predict_pref_i = pref_predict_layer(batch_user_embed,  batch_item_embed).view(-1)\n",
    "            batch_predict_pref_g = pref_predict_layer(batch_group_embeds, batch_item_embed).view(-1)\n",
    "            batch_predict_pref = (1 - user_group_ratio[batch_user]) * batch_predict_pref_i + user_group_ratio[batch_user] * batch_predict_pref_g\n",
    "\n",
    "            # batch_predict_rate =  item_avg[batch_item] +   item_std[batch_item] * batch_predict_pref + user_bias[batch_user]\n",
    "            batch_pref =  (batch_rate - user_bias[batch_user] - item_avg[batch_item] )/ item_std[batch_item]\n",
    "\n",
    "            batch_loss = loss_func(batch_predict_pref *10, batch_pref  * 10)   + torch.abs(torch.sum(user_bias))/torch.sum(torch.abs(user_bias)) \n",
    "            # batch_loss = loss_func(batch_predict_pref *10, batch_pref *10 )   \n",
    "                            \n",
    "            opt.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            opt.step()\n",
    "            epoch_loss  += batch_loss.item() / batch_num\n",
    "\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # data = rating_data_test\n",
    "            data = rating_data_valid\n",
    "            test_user_ids, test_item_ids = data[:,0], data[:,1]\n",
    "            rate = torch.tensor(data[:,2]).float().to(device)\n",
    "\n",
    "            user_embeds, group_embeds, item_embeds  = node_embed_layer(node_onehot_tensor)\n",
    "            test_user_embed = user_embeds[test_user_ids]\n",
    "            test_group_embeds = group_embeds[test_user_ids]\n",
    "            test_item_embed = item_embeds[test_item_ids]\n",
    "         \n",
    "            predict_pref_i= pref_predict_layer(test_user_embed, test_item_embed).view(-1) \n",
    "            predict_pref_g= pref_predict_layer(test_group_embeds, test_item_embed).view(-1) \n",
    "            predict_pref = (1 - user_group_ratio[test_user_ids]) * predict_pref_i + user_group_ratio[test_user_ids] * predict_pref_g\n",
    "\n",
    "            predict_rate =  item_avg[test_item_ids] +   item_std[test_item_ids] * predict_pref + user_bias[test_user_ids]\n",
    "            # predict_rate =  item_avg[test_item_ids]  + user_bias[test_user_ids]\n",
    "            predict_rate = predict_rate.clamp(1,5)\n",
    "            # predict_rate = torch.round(predict_rate)\n",
    "\n",
    "            if i == 15:\n",
    "                # print(predict_pref[:10])\n",
    "                # print(item_avg[test_item_ids][:10])\n",
    "                # print(rate[:10])\n",
    "                # print(predict_rate[:10])\n",
    "                print(user_group_ratio[:20])\n",
    "                print(user_bias[:20])\n",
    "                # print(node_embed_layer.pref_embeding.weight)\n",
    "                print(dataProcess.get_recall(predict_rate,rate,4))\n",
    "                # print( predict_pref[:100])\n",
    "                return\n",
    "\n",
    "\n",
    "            test_loss = dataProcess.get_rmse(predict_rate, rate)\n",
    "            test_mae = dataProcess.get_mae(predict_rate, rate)\n",
    "\n",
    "        print(\"epoch :\",i + 1,end=\"\\t\")\n",
    "        print(\"train Loss:\", epoch_loss,end=\"\\t\")\n",
    "        print(\"test RMSE:\", test_loss, \"     test MAE: \", test_mae)    \n",
    "        if test_loss < min_test_rmse:\n",
    "            min_test_rmse = test_loss\n",
    "            min_test_mae = test_mae\n",
    "        if i>0 and i % 20 == 0:\n",
    "            dataProcess.adjust_learning_rate(opt)\n",
    "    \n",
    "    with open(\"utils/log.md\",\"a\") as f:\n",
    "        f.write(\"# Modify:   \\n\")\n",
    "        f.write(\"   r1 r2, r3: {}, {}, {} \\n\".format(r1,r2,r3))\n",
    "        f.write(\"   Train_Loss:{}   test_MSE:{}    test_mae: {}\\n\".format( epoch_loss, min_test_rmse, min_test_mae))\n",
    "        \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('GDS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c467baaf01baace5d9c3c3dc3724781038ef566c91383523066af079a91c06fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
